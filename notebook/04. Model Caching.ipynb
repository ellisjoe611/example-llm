{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache, get_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "if not get_llm_cache():\n",
    "    set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm: ChatOllama = ChatOllama(model=\"llama3.2:3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template: str = \"\"\"\n",
    "You are the Python code generator according to user's request.\n",
    "Here's the request you will get:\n",
    "{request}\n",
    "Write a complete source code in Python as the answer.\n",
    "If accepting the request not related to the programming, do not answer.\n",
    "Just answer it in source code only, not anything else.\n",
    "\"\"\"\n",
    "\n",
    "prompt: PromptTemplate = PromptTemplate(template=template, input_variables=[\"request\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request: str = \"Write me an fibonacci function in dynamic programming.\"\n",
    "\n",
    "for chunk in chain.stream(input={\"request\": request}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
